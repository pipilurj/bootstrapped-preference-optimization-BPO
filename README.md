<div align="center">
    <img src="images/logo.png" alt="BPO" width="128px">
<p>Generated by <a href="https://openai.com/dall-e-3">DALL·E 3</a></p>
</div>

This repository contains the code for the paper titled "Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization". [[Link to our paper](https://arxiv.org/abs/2403.08730)]
## Install Packages

```

conda create -n bpo python=3.10 -y

conda activate bpo

pip install -e .

```
## Training data
Download ShareGPT4V from [here](https://huggingface.co/datasets/Lin-Chen/ShareGPT4V)

Download COCO from [here](https://cocodataset.org/#home)

Download dataset annotation from [here](https://huggingface.co/datasets/renjiepi/BPO)

Extract  data from ShareGPT4V and organize the images as follows:

```
Image_root
├── coco/
    ├──train2017/
├── llava/
    ├──llava_pretrain/
├── sam/
├── share_textvqa/
    ├──images/
├── web-celebrity/
    ├──images/
├── web-landmark/
    ├──images/
├── wikiart/
    ├──images/
```

## Train BPO

```
bash scripts/finetune_bpo.sh
```


## Acknowledgement
The project is built on top of the amazing multimodal large language model [LLaVA](https://github.com/haotian-liu/LLaVA), RLHF package [trl](https://github.com/huggingface/trl), DPO for multimodal learning [Silkie](https://github.com/vlf-silkie/VLFeedback), and visual contrastive decoding [VCD](https://github.com/DAMO-NLP-SG/VCD).
Thanks for these great work!


If you find our work useful for your research or applications, please cite using this BibTeX:
```bibtex
@misc{pi2024strengthening,
      title={Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization},
      author={Renjie Pi and Tianyang Han and Wei Xiong and Jipeng Zhang and Runtao Liu and Rui Pan and Tong Zhang},
      year={2024},
      eprint={2403.08730},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
